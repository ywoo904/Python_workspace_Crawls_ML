## 통계적 추정
# 통계학 배우는 이유? 
# 통계학에서 실제 전체 집단에 대한 특성을 알고 싶을 떄 현실적으로 가능할까? 
# 실제로 전체 집단에 대한 자료를 구하는 것은 쉽지 않은 일이란 점이다(돈 & 시간) 
# 집단 전체가 아닌 일부 표본을 통해서 집단을 통해서 전체에 대해서 추론하는 것 
## Ex) 여론조사(선거철) 
# 이런 이유로 우리는 올바른 통계적 추론 방법을 사용하는 것이 매우 중요합니다.

## 통계적 추정의 종류 
# 통계학에서 모집단(Population)과 표본(Sample)을 구분한다 
# 모집단은 우리가 여러번 언급한 관심을 가진 전체집단이고 표본이란 random sample을 말함 
# 표본의 모집단의 일부를 의미합니다. 여기서 표본이란 임의표본은 모집단의 모든 구성원에게 표본에 포함될 기회를 똑같이 주고 추출한 표본, 그리고 
# 특정단위가 선택될 확률은 다른 단위가 선택될 확률과 독립적이다. 
# "독립적이면서도 동일하게 분포된 (Independent and Identically Distributed)"라고 표현 => IID 
# 모집단에서 표본을 얻으면 그것을 바탕으로 모집단에 대해서 추정하는데,
# 통계적 추론으로 1)점추정(point estimation)과 2)구간추정(interval estimation)이 있다. 

## 점추정 
# 점추정은 관심을 갖고 있는 숫자, 이를테면 모집단의 평균, 비율 등과 같이 하나의 숫자로 "찍는" 것을 말한다. 
# 모집단의 평균과 비율은 모평균, 모비율로 말하는 방식으로 모집단의 수치를 표시한다. 
# 같은 방식으로 표본집단의 평균도 표본평균, 표본비율이라고 부릅니다.
# 모집단의 특정값을 알기 위해서는 표본에서 같은 특정 값을 사용하여 추정하는 것이 맞다. 
# 그래서 표본집단의 특정값 예로 평균을 점추정하여 모집단의 평균을 구하는 것이다. 
# 예시) "한국의 20대 여성"이라는 모집단의 키평균을 추정, 100의 표본을 추출하여 
# 키의 표준평균을 계산한다음 그것을 모평균의 추정치로 사용하는 방식.
# 같은 방식으로 모비율에 대한 측정, 표준편차에 대한 추정도 가능하다. 

## 표집오차(Sample Error), 표준오차(Standard Error)
# 모집단에서 임의표본을 추출한다는 것은 각각의 단위에 뽑힐 기회가 무작위적으로 주어진다는 것을 뜻한다. 
# 이는 추출할 때마다 표본이 달라지고 표본의 평균이나 표본비율도 달라질 수 있다. 
# 이런현상을 통계학에서는 "표집오차(sampling error)" 라고 합니다. 
# 이 표집오차로 인해 표본의 평균, 비율은 일치하지 않을 경우가 대부분인 것을 알 수 있다.
# 하지만 일치하지 않는 정돈는 어떤 범위내로 정해져있을 것이다. 이 정도를 표준오차(Standard Error)라고 함. 
# 이 표준오차가 작은 추정방식일 수록 좋은 추정방식이 된다.  
# 표준오차를 알고 있다면 구간추정을 할 수 있습니다. 

## 구간추정 
# 위에서 말한 표준오차를 알고 있다면 구간추정을 할 수 있습니다. 
# 점추정의 하나의 숫자를 찍는 것과 달리 구간추정은 모수치가 대략 어디에서 어디 사이에 있을 것이라고 예상하게 해줌. 
# Ex)선거에서 특정 후보의 지지율을 단순히 40%라고 하지 않고, 38.5~41.5% 사이에 있다고 하는 경우를 구간추정이라고 볼 수 있다. 
# 점추정과 다른점은 하나의 숫자만 전달하는게 아닌 '불확실성'의 정보를 같이 추정하는 것 
# 여기서 "신뢰구간" 또는 "신뢰도"라는 말을 했다면 보통 구간추정을 했다는 의미 

## 모평균의 추정 
# 표본평균은 모평균에 대해서 즐겨 사용한 점추정치로 여러가지 좋은 성질을 가지고 있다. 
# 1) Unbiased
# 모집단에서 추출을 계속하면서 표본평균을 계산한다면 그 기댓값은 모평균에 일치합니다 
# Ex) 앞에서 이야기 한 "20대 한국여성"이라는 모집단의 키의 평균을 구하는 것을 생각해보자  
# 이미 키의 평균은 정해져 있을 것이지만 우리는 정확히 알지 못한다면, 모집단에서 임의의 100명씩 표본을 추출하여 평균을 계산하는 것을 반복합니다. 
# 그리고, 표본을 추출한 100명은 평균을 계산한 다음에 다시 모집단으로 돌려보낸다. 즉 복원추출을 한다는 의미.
# 이렇게 1000번 반복한 다음에 이 1000개의 표본평균을 얻을 수 있다. 그리고 이 값들의 평균을 구하면 이것이 평균의 평균이다.
# 불편성은 이렇게 평균을 한없이 모으면 그 값들은 평균의 모평균과 일치한다는 것을 말함  
# 불편성은 포본평균을 모평균에 대한 추정치로 사용할 때 모평균에 비해 작거나 큰 값으로 치우치는 경향이 없다는 것을 보장하는 것. 
# 이 추정치를 불편추정치라고 한다.  
# 반면 음이나 양의 방향으로 치우치지 않는 경향이 있는 추정치를 "편의 추정치"라고 한다. 

## 2) 최소분산(Minimum Variance) 
# 표본평균 말고도 모평균에 대해 불편 추정치를 만들 수 있는데, 자료를 많이 못모았다고 하더라도
# 그 중 첫번째 값만 떼어 대표값인 것처럼 간주하여 모평균에 대한 추정치로 사용할 수 있습니다. 그러면 그 기댓값이나 평균은 모평균과 같을 수 있습니다. 
# 하지만 이런 방식은 표본평균에 의해 변동성이 훨씬 크다. 
# 수학적인 증명이 있으나 여기서는 단순히 자료의 수가 적으면 정보의 양도 적다는 것을 의미함. 
# 위에 이야기한 표본평균은 모평균에 대한 불편추정치 중 변동성이 가장 작습니다. 이는 모평균과 가장 가깝다는 의미이고, 
# 이것을 "최소 분산"의 의미가 됩니다. 
# 여기서 분산은 변동성을 측정하는 단위의 하나라고 이해한다. 

## R을 이용한 표본평균 시뮬레이션  
# 불편성은 직접 시뮬레이션을 하지 않으면 이해하기 쉽지 않은 개념입니다. 
# 모집단이 특정 자료가 아니라 확률분포라고 가정합니다. 
# 확률분포는 자료가 무한히 많은 모집단처럼 간주하기도 합니다. 
# 평균이 170이고 표준편차가 15인 확률분포, N(170,15^2)를 모집단으로 생각합니다. 
# 이것은 어떤 가상집단의 키의 분포라고 생각할 수 있다. 이 모집에서 표본평균의 추출작업을 반복하여 값을 구합니다.  
# 난수 생성 시 시드 고정 
set.seed(1234) # 참고, 시드값을 아무거나 넣어도 상관없음. 대신 같은 값이면 고정된 결과 

# 표본평균 갯수
n_sim = 10000

# 각 표본의 크기 
sample_size = 100
means = c()   # 표본값을 저장할 벡터생성

           #10000번 반복 
for (i in 1:n_sim) { 
    data = rnorm(sample_size, 170, 15) #확률분포  
    means= c(means,mean(data)) #평균값을 10,000개 추출 
} 

hist(means, xlab = "X", ylab = "N", main="", prob = T, breaks= 50)
curve(dnorm(x,170,15/sqrt(sample_size)),160,180,add=T, lty=2 ,lwd=2, col= "red")

# 출력된 그래프를 확인하면 완벽하지는 않지만 표본평균의 분포는 대충 종형곡선에 가까운 것을 확인할 수 있다. 
# 이것은 앞에서 말한 표본평균의 분포는 정규분포를 따른다는 "중심극한정리"의 결과입니다.
# 시뮬레이션 횟수를 더 늘리면 곡선이 실제 자료에 점점 더 잘 들어맞게 됩니다. 
# 통계학에서는 "fit"이 좋아진다고 합니다.
# 이 분포의 표준편차는 모집단의 표준편차인 15를 표본의 크기인 100의 제곱근, 즉 10으로 나눈 것과 같다.  
# 일반적으로 표본평균의 표준편차는 모집단의 표준편차에 비해
# "표본의 크기의 제곱근의" 역배수만큼 작습니다. 즉, 여기서는 표본평균의 표준편차는 1.5가 된다(표준오차)
# 실질적으로 모 표준편차를 모르기 때문에 다른 방식으로 추정한 뒤에 그것을 대신 사용합니다.

# 이 시뮬레이션을 하기 전에 표본평균은 모평균에 대한 불편추정치라고 하였다. 
# 이것이 사실이라면 표본평균은 평균의 모평균에 가까워야 한다. 
# 위 시뮬레이션에서 표본평균의 평균을 구하면, 
mean(means) # [1] 170.0066, 모집단의 평균과 일치 

# 또한 정규분포는 매우 유용한 성질을 가지고 있다
# 평균에서 +-(2*표준편차) 영역 안에 95%가량의 자료가 포함되어 있다. 
# 여기서 표본평균의 경우에도 (2*표준오차)라고 할 수 있다. 
se = 15/sqrt(sample_size) # (표준오차) Standard Error 1.5 
means_within_2se=(means>170-2*se) & (means<170+2*se) #167~173
# 안에 맞아 떨어지게 되면 "모집단의 평균"으로 간주할 수 있다. 
sum(means_within_2se) #9514 

# Standard Error는 표준편차를 각 표본의 크기에 대한 루트값으로 나눈 것. 
# 위에서 계산한 것 같이 1.5가 나온다.  

# 두번째, 표본평균이 위에 170 +-(2 x 표준편차) 안에 포함되는지 여부를 각각 알아본 뒤  
# means_within_2se에 저장, 이때 결과는 True or False 로 저장  
# 각각의 TRUE는 1로, False는 0으로 취급되고, 이들의 합을 구하면 전체 시행 횟수에 따른 
# 얼마나 TRUE가 나왔는지를 알 수 있게 된다. 그 값은 95.14%로 95%라는 값과 대략일치 

## 모평균에 대한 구간추정 
# 표본평균이 정규분포를 따른다는 것을 시뮬레이션으로 증명함  
# 이것을 통계학적으로 표현하면, 자료가 평균이 m, 표준편차가 s인 어떤 분포를 따른다고 가정할 때, 
# 이 분포의 크기인 n이 표본을 추출하여 표본평균을 구하는 일을 반복할 때, 
# n이 커짐에 따라 표본평균은 근사적으로 다음과 같은 정규분포를 따른 것으로 알려져 있다.

# N(m,s^2/n)
# 표본평균의 분산, s^2/n은 자료의 크기에 반비례하여 작아집니다. 
# 이 사실을 확인하여 다음이 성립할 수 있다. 
# 원래는 x 바로 표현하나 지금은 그냥 대문자 X로 표현 -> 
# X=표본평균 / m= 평균
# *********P(m - 2*s/sqrt(n)< X < m + 2*s/sqrt(n)) ~=(근사)0.95
# 이것은 표본평균이 모평균으로부터 +-(2* 표준오차) 안에 있을 확률은 95%이다를 수학적으로 표현한 것 

# 첫번째 부등식, (m - 2*s/sqrt(n)< X)를 이항하면, 
# m < X + 2*s/sqrt(n)

# 두번째 부등식, (X < m + 2*s/sqrt(n))도 이항하면, 
# m > X - 2*s/sqrt(n) 
# 두 부등식을 합치면, 
# X - 2*s/sqrt(n) < m < X + 2*s/sqrt(n)
# P(X - 2*s/sqrt(n) < m < X + 2*s/sqrt(n)) ~= 0.95
# => 모평균은 표본평균의 범위에 따라 결정된다! 

# **중요** 
# 여기서 "무작위"인 것, 즉 표본을 추출할 때마다 달라지는 것은 모평균이 아닌 표본평균이다. 
# 즉, 위 평균 m이고, 표준편차 s인 모집단의 표본평균을 계속 모으면 그 중 95%에서 m은 평균에서 (2*표준오차) 안에 들어온다는 것을 의미 
# 신뢰구간은 이와 같이 표본평균 +-(2*표준오차)는 모평균에 대한 95% 신뢰구간이라고 한다.
# 이것은 달리 말하면, 모집단에서 계속 표집하면서 95% 신뢰구간을 만들면, 그중에 95%가 모평균을 포함한다는 것을 의미하게 된다. 

# R로 95% 신뢰구간의 성질 확인하기 
# 난수 생성시 시드고정  
set.seed(1234) 
n_sim = 10000  # 표본평균 갯수 
sample_size = 100 # 각 표본의 크기   
m= 170 # 평균 
s= 15 # 표준편차 
se= s/sqrt(sample_size) 
X_bar_in_CI = c() 

# 정규분포에서 표집 후 평균값을 저장 
for (i in 1:n_sim) { 
    data = rnorm(sample_size,m,s)
    X_bar = mean(data) 
    
    if((X_bar - 2*se<m) & (X_bar + 2*se >m )){ 
        X_bar_in_CI = c(X_bar_in_CI, TRUE)
    } else{ 
        X_bar_in_CI = c(X_bar_in_CI, FALSE)
    }
}

# 신뢰구간 안에 모평균이 포함될 비율 
mean(X_bar_in_CI) #0.9514 ~= 95.14%  

# 계산값 확인하면 95%에 가까운 숫자가 나온다. 
# 작성한 신뢰구간, (X_bar - 2*se, X_bar +2*se)가 실제로 95%의 경우 모평균을 포함한다는 것을 확인해주는 결과입니다. 

## 신뢰구간의 사용에 대한 팁 
# -지금까지 이야기한 모평균에 대한 95% 신뢰구간은 표본평균에 대해 대칭 
# -따라서 양 끝 값울 더한 뒤 2로 나누면 표본평균이 얼마인지 알 수 있다 
# -신뢰도(앞서 이야기한 95% 신뢰구간..)는 높아질 수록 구간의 길이는 길어진다
# -높은 확률로 모평균을 잡아내려면 신뢰구간을 넓게 잡아야 그 안에 떨어질 확률이 높아질 것입니다
# -하지만 신뢰구간의 길이가 길수록 신뢰구간 자체의 유효성은 떨어진다
# -즉 신뢰가 높다고 해서 꼭 좋은 것은 아니다. 범위가 커져서 평균값에 대한 범위가 모호해질 수 있다.
# -신뢰도로 추정할 때 표본크기가 커질수록 신뢰구간의 길이는 짧아진다 (표준오차가 적다) 
# -수학적으로 신뢰구간의 길이는 표준오차에 비례하게 된다. 
# -모평균에 대한 95% 신뢰구간의 경우 대략 (4*표준오차) 정도 됩니다. 
# -그런데 표준오차 자체가 모 표준편차를 sqrt(n)으로 나눈 것이고, n이 커질수록 표본오차가 작아지기 때문에 결국 신뢰구간의 길이도 짧아지게 된다.   
# -직관적으로 표본크기를 늘릴 수록 신뢰구간의 길이는 짧아지게 되고, 이는 더 정밀한 구간추정을 할 수 있다는 의미가 된다. 
# -하지만 표본크기를 늘리는 것은 돈과 그 밖의 자원문제가 생기기 때문에 적당한 선에서 타협할 수 밖에 없다. 

## 부트스트랩 
# -현대 통계학자들이 진보된 계산 기술을 받아들여 기존 수학공식을 이용한 방식이 잘 통하지 않는  
# 경우에도 폭넓게 적용할 수 있는 강력한 추론기법을 의미
# -부트스트랩을 활용하면 앞에서 살펴본 신뢰구간 공식이든 뭐든 전혀 사용하지 않고,
# 컴퓨터 시뮬레이션만으로도 평균을 추정하고, 신뢰구간을 만들 수 있습니다. 

## 부트스트랩 원리 
# -앞서서 관심을 가진 모집단, "20대 한국남성"과 같은 모집단의 전수자료에 접근할 수 없기 때문에 
# 표본을 추출하고, 그것을 가지고 통계적 추정을 한다. 
# -모집단의 특정 가정하에 표본을 계속 추출한다고 했을 떄 실제 관측한 표본이 그 중에 어느 위치에 있는지를 생각했습니다 
# -이런 발상을 전환하여 우리가 표본 자체가 일종의 모집단 인 것 처럼 넘기는 방법은 없을까? 
# -> 이 과정을 받아들이면 그 가상의 모집단에서 계속 표본을 추출하여 평균을 계산하고 그것들을 모아 분포를 만들 수 있다. 
# 이것은 우리가 컴퓨터로 지금까지 해온 방식이며, 쉽게 할 수 있는 작업ㄴ이다. 이것이 바로 부트스트랩 방식이다.  
 
##부트스트랩의 장점 
# 추정에 필요한 수학공식을 모르거나 애초에 존재하지 않아도 관심있는 대상, 즉앙값 등에 대한 분포를 만들고 신뢰구간도 만들 수 있씁니다. 
# 표본평균의 경우 표본평균이 중심극한정리에 근사적으로 정규분포에 따른다는 점을 이용하여 95% 신뢰구간을 만들때, 표본평균 +-(2*표준오차)공식을 사용했다. 
# 이것은 중심극한 정리가 적용되지 않는 대상, 또는 구간 추정 공식을 모르는 대상에 대해서는 적용할 수 없습니다. 
# 부트스트랩을 사용하면 신뢰구간을 간편하게 얻을 수 있다. 

## R에 내장된 데이터셋을 이용하여 부트스트랩 방식을 실습함(자료: 붓꽃 iris) 
iris # 붓꽃데이터
class(iris) # 데이터타입: [1] "data.frame"
head(iris) #  Sepal.Length / Sepal.Width / Petal.Length / Petal.Width / Species 

## 부트스트랩 모평균 추정하기 
# iris는 데이터세트로 총 5가지 변수를 가지고 있습니다.
# 150개의 데이터가 각각 꽃잎(Petal), 꽃받침(Sepal), 각 길이(Length)와 너비(Width), 종(Species)으로 기록된 자료입니다.  

# 여기서는 종이 setosa종의 꽃잎길이의 모평균에 대해서 점추정과 구간추정을 해봅니다. 
iris$Petal.Length
# 꽃잎 길이변수는 데이터세트 안에 Petal.Length라는 이름으로 저장되어 있습니다
# 추정공식을 사용하면 모평균에 대한 점추정치는 표본평균과 같고, 구간 추정치는 (2 * 표준오차)를 더하거나 뺀 것으로 만들 수 있음. 
# 예제는 sqrt(50)으로 나눈 것과 같다 
# 주의할 점: 앞에서 보았던 예제들은 모집단의 표준편차를 정확히 안다고 가정했다
# 지금 setosa종의 모 표준편차를 안다고 가정할 수 없다 
# 그러므로 여기서는 표본에서 추정한 표준편차를 사용합니다 
# 정규분포 추정공식을 바로 이용할 수 없음. 
# 이렇게 되면 정규분포를 적용할 수 없고, 정규분포를 근사하는 분포인 t분포를 사용해야 합니다. 
# 하지만 t분포는 표본크기가 충분히 크면 정규분포에 가까워지고, 이를 적용가능하지만, 지금 현재는 관심사가 아니다. 
# 정규분포 추정공식을 사용할 것이다. 

# 1) 먼저 setosa 자료만 따로 추출한다. 실행함수는 subset()/ 부분집합을 만들어 저장 
y <- subset(iris, Species=='setosa')$Petal.Length  

# 2) 이 값들의 평균을 구함
mean(y)  # [1] 1.462  모평균 *Bootstrap은 표본평균을 '모평균' 취급한다. 

# 3) 다음으로 95% 신뢰구간을 만듬(SD required) 
# R의 표준편차(sd)를 구하는 함수 sd() 
sd(y) # [1] 0.173664 모표준편차 *BootstraP은 표본편차를 '모편차' 취급한다.  

##이제 이 값을 당분간 모 표준편차처럼 사용합니다. 
# 그리고 표준 오차를 구하고 신뢰구간을 다음과 같이 처리한다. 

n <- length(y) # 50개 
ci_low <- mean(y)-2*sd(y)/sqrt(n) 
ci_upper <- mean(y)+2*sd(y)/sqrt(n) 
print(c(ci_low,ci_upper))  # 1.41288 1.51112 
# 1.41보다 크고 1.51 작은 범위안에 있는 값 

## 이제 모평균에 대한 구간추정공식을 모른다고 치고 부트스트랩 방식으로 추정 ** 
# 앞에서 부트스트랩은 가상의 모집단인 표본에서 추출하는 방식이기 때문에 이를 위한 시뮬레이션 코드를 작성해야함  
n_sim <- 10000 
means <- c()  #평균 벡터에 저장 

for (i in 1:n_sim)  {             
    bs_sample <- sample(y,length(y),replace=T)   #복원추출(매우중요), ***Bootstrap은 표본추출 할때 표본 길이만큼 "복원추출한다"
    sample_mean <- mean(bs_sample)
    means <- c(means,sample_mean) # 평균값 1만개 생성
} 

head(means,12L) 

# 여기서 중요한 것은 sample 입니다.
# 첫번째 입력값인 y로부터 무작위로 표본추출을 하는데 그 표본의 크기가 두번째 입력값과 같습니다. 
# 여기서부터 부트스트랩에 중요한 것은 원자료에서 표본을 추출할 때 정확히 같은 크기만큼 추출해야 한다는 점(***), 
# 세번째로 replace= True 로 복원추출을 해야한다는 것(필수) 
# 이렇게 구해진 means를 이용하여 신뢰구간을 만들 수 있다 
# 95% 신뢰구간은 값들을 정렬했을 때 가운데의 95%에 해당하는 값들의 범위를 의미 
# 이것은 상위, 하위 2.5%에 해당하는 값들을 찾으면 그것들로 신뢰구간 상한, 하한을 구할 수 있게된다.
# 이때 사용하는 함수가 quantile()입니다. 이 함수의 특징은 자료를 작은 것부터 큰것순으로 나열
# 할 때 주어진 비율에 해당하는 값이 무엇인지 알려준다.

# 정규분포의 quantile 
quantile(means,.025) # 하위 2.5%를 의미 결과: 1.414 ci_lower와 근사값
quantile(means,.975) # 상위 2.5%를 의미 결과: 1.51 ci_upper와 근사값  

# 결과적으로 95% 신뢰구간인 1.41,1.51과 거의 일치합니다. 
# 부트스트랩은 수학적인 공식을 전혀 사용하지 않고 오로지 컴퓨터와 시뮬레이션의 힘으로 값을 구해낸다. 

## t분포(모 표준편차를 모를 떄 표준정규분포 대신에 사용하는 일종의 근사 -> 표준편차를 모를 때 
# t분포는 표준정규분포와 매우 비슷하다. 종형 모양에 가깝고 0에 대해 대칭적이지만 분포 끝부분에 더 많은 자료가 흩어져 있다는 것이 특징.
# 자료가 많을 수록 "정규분포와 근사" 
# 꼬리의 두께는 자유도(Degree of Freedom)에 의해 결정되고, 정규분포가 평균과 표준편차 두 개의 값으로 결정되는 것과 달리 t분포는 자유도만으로 결정된다. 
# 자유도는 낮을 수록 꼬리가 두꺼워 지고 높을수록 얇아져 t-분포는 결국 표준정규분포에 가까워지게된다.
# 쉽게말해 자유도가 높다는 것은 데이터가 그만큼 많다는 것 이다.  
# t-분포의 자유도는 표본크기에서 1을 뺀 것, 즉 (n-1)과 같습니다. 이것을 사용하여 다시 95% 구간을 추정할 수 있습니다. 
# t분포의 상한과 하한을 구하기 위해서 qt()를 사용합니다. 
# T분포의 quantile 

y <- subset(iris, Species=='setosa')$Petal.Length  
n <- length(y) # 50개 
c(mean(y)+qt(.025,df=n-1)*sd(y)/sqrt(n),mean(y)+qt(.975,df= n-1)*sd(y)/sqrt(n))

#     하한      상한 
# [1] 1.412645 1.511355

## 부트스트랩 이용한 표준편차 추종하기  
# 추정 공식을 아직 모르는 대상에 대해서 구간 추정하는 것을 확인 (모표준편차)
y <- subset(iris, Species=='setosa')$Petal.Length  
n_sim <- 10000 
sds <- c()
n <- length(y) # 50개 

for (i in 1:n_sim) {  
    bs_sample = sample(y,length(y),replace=T) 
    sample_sd = sd(bs_sample)
    sds = c(sds,sample_sd)
}
c(quantile(sds,.025),quantile(sds,.975)) # 0.1300549 0.2101117 
(quantile(sds,.025)+quantile(sds,.975))/2

##구간추정공식(수학적공식)- 모 표준편차에 대한 구간추정 공식을 생략 
sqrt(var(y)*(n-1)/qchisq(.975,n-1))
sqrt(var(y)*(n-1)/qchisq(.025,n-1))

# 공식에 의한 값은 실제로 부트스트랩을 사용한 경우와 비교했을 때에 큰 차이가 나지 않는다. 
# 이는 각종 수학적 과정과 표본크기 등의 문제 때문에 복잡하니 생략  
# 중요한 것은 구간 추정법을 모르는 대상도 점추정법만 알면 복원 추출을 통해 구간추정을 할 수 있다 ->Boststrp을 이용하는 이유 

#[1] 0.2164085 
